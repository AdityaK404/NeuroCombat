# NeuroCombat v5 ðŸ¥Š

**Real-time MMA Move Recognition System with Dual-Fighter Tracking & Live Commentary**

[![Python 3.11+](https://img.shields.io/badge/python-3.11+-blue.svg)](https://www.python.org/downloads/)
[![PyTorch](https://img.shields.io/badge/PyTorch-2.1-red.svg)](https://pytorch.org/)
[![Redis](https://img.shields.io/badge/Redis-7.0-red.svg)](https://redis.io/)
[![License: MIT](https://img.shields.io/badge/License-MIT-yellow.svg)](https://opensource.org/licenses/MIT)

## ðŸŽ¯ Overview

NeuroCombat v5 is a **production-grade, modular, real-time ML pipeline** for MMA move recognition that:

- âœ… **Processes 30-60 FPS** with <50ms end-to-end latency
- âœ… **Tracks dual fighters** using ByteTrack multi-object tracking
- âœ… **Ensemble AI models** (Bi-LSTM + Transformer) with Bayesian fusion
- âœ… **Live natural-language commentary** with TTS generation
- âœ… **Horizontally scalable** via Redis Streams + async workers
- âœ… **Production observability** (Prometheus, Grafana, Jaeger)

---

## ðŸ—ï¸ Architecture

```
Video Stream (30-60 FPS)
    â†“
Pose Extraction (MediaPipe/MoveNet + GPU)
    â†“
Dual Fighter Tracker (ByteTrack)
    â†“
Motion Features (Velocity + Acceleration â†’ 198D)
    â†“
Sequence Model (Bi-LSTM + Transformer + GPU)
    â†“
Ensemble Fusion (Bayesian Weighting)
    â†“
â”œâ”€â†’ Commentary Engine (TTS)
â”œâ”€â†’ Dashboard (WebSocket)
â””â”€â†’ Replay Buffer (Redis TimeSeries)
```

**See [ARCHITECTURE.md](ARCHITECTURE.md) for complete design blueprint.**

---

## ðŸš€ Quick Start

### Prerequisites

- **Python 3.11+**
- **Redis 7+** (with Streams support)
- **NVIDIA GPU** (optional but recommended, CUDA 11.8+)
- **Docker & Docker Compose** (for containerized deployment)

### Installation

```powershell
# Clone repository
git clone https://github.com/your-org/neurocombat-v5.git
cd neurocombat-v5

# Install dependencies (Poetry)
poetry install

# Or using pip
pip install -e .

# Setup Redis Streams
python scripts/setup_redis_streams.py
```

### Run with Docker Compose

```powershell
# Start all services
docker-compose up -d

# View logs
docker-compose logs -f

# Stop services
docker-compose down
```

### Access Services

- **Dashboard**: http://localhost:8000
- **Prometheus**: http://localhost:9090
- **Grafana**: http://localhost:3000 (admin/neurocombat)
- **Jaeger UI**: http://localhost:16686

---

## ðŸ“¦ Project Structure

```
neurocombat_v5/
â”œâ”€â”€ src/neurocombat/
â”‚   â”œâ”€â”€ schemas/          # Pydantic data models
â”‚   â”œâ”€â”€ core/             # Redis client, logging, metrics
â”‚   â”œâ”€â”€ modules/          # Pipeline components
â”‚   â”‚   â”œâ”€â”€ pose_extraction/
â”‚   â”‚   â”œâ”€â”€ tracker/
â”‚   â”‚   â”œâ”€â”€ motion_features/
â”‚   â”‚   â”œâ”€â”€ sequence_model/
â”‚   â”‚   â”œâ”€â”€ ensemble/
â”‚   â”‚   â”œâ”€â”€ commentary/
â”‚   â”‚   â””â”€â”€ dashboard/
â”‚   â””â”€â”€ tests/
â”œâ”€â”€ config/               # YAML configurations
â”œâ”€â”€ models/               # Pre-trained weights
â”œâ”€â”€ docker/               # Dockerfiles
â”œâ”€â”€ kubernetes/           # K8s manifests
â”œâ”€â”€ scripts/              # Utility scripts
â””â”€â”€ notebooks/            # Jupyter experiments
```

---

## ðŸŽ® Usage

### Python API

```python
import asyncio
from neurocombat.core.config import load_config
from neurocombat.modules.pose_extraction.worker import PoseExtractionWorker

async def main():
    # Load configuration
    config = load_config(environment="production")
    
    # Start pose extraction worker
    worker = PoseExtractionWorker(config)
    await worker.run()

if __name__ == "__main__":
    asyncio.run(main())
```

### CLI

```powershell
# Run specific worker
neurocombat worker --component pose_extraction --config config/base.yaml

# Run full pipeline
neurocombat pipeline --video-source 0 --gpu

# Export model to ONNX
neurocombat export --model bilstm --output models/bilstm_v1.onnx
```

---

## ðŸ“Š Data Contracts

### PoseFrame (33 joints Ã— 4D)

```json
{
  "frame_id": 12345,
  "timestamp_ms": 1699700000000,
  "fighter_id": "fighter_1",
  "joints": [
    {"x": 0.5, "y": 0.3, "z": -0.1, "visibility": 0.95},
    ...
  ],
  "model_source": "mediapipe",
  "bbox": [0.2, 0.1, 0.8, 0.9]
}
```

### MotionVector (198D features)

```json
{
  "frame_id": 12345,
  "timestamp_ms": 1699700000000,
  "fighter_id": "fighter_1",
  "velocity": [0.01, 0.02, ...],      // 99 floats
  "acceleration": [0.001, -0.003, ...], // 99 floats
  "velocity_norm": 0.45
}
```

### PredictionPacket

```json
{
  "prediction_id": "uuid-1234",
  "frame_id": 12345,
  "timestamp_ms": 1699700000000,
  "fighter_id": "fighter_1",
  "predicted_label": "hook",
  "confidence": 0.87,
  "class_probabilities": {
    "jab": 0.05,
    "cross": 0.08,
    "hook": 0.87
  },
  "model_name": "ensemble",
  "inference_time_ms": 22.3
}
```

---

## ðŸ”§ Configuration

### Environment Variables

```powershell
# Redis
$env:NEUROCOMBAT_REDIS__URL = "redis://localhost:6379"

# Video source
$env:NEUROCOMBAT_VIDEO__INPUT_SOURCE = "0"  # Webcam
$env:NEUROCOMBAT_VIDEO__TARGET_FPS = "30"

# GPU device
$env:NEUROCOMBAT_POSE_EXTRACTION__INFERENCE_DEVICE = "cuda:0"

# Logging
$env:NEUROCOMBAT_LOGGING__LEVEL = "INFO"
```

### YAML Configuration

See [config/base.yaml](config/base.yaml) for all available options.

---

## ðŸ§ª Testing

```powershell
# Run unit tests
pytest src/neurocombat/tests/unit/

# Run integration tests
pytest src/neurocombat/tests/integration/

# Run with coverage
pytest --cov=neurocombat --cov-report=html

# Load testing (Locust)
locust -f src/neurocombat/tests/load/test_pipeline.py
```

---

## ðŸ“ˆ Performance Benchmarks

| Metric | Target | Measured (T4 GPU) |
|--------|--------|-------------------|
| **End-to-end latency** | < 50ms | ~45ms |
| **Throughput** | 30 FPS | 32 FPS |
| **Pose extraction** | < 15ms | 12ms |
| **Sequence model** | < 25ms | 20ms (batch=4) |
| **Memory** | < 2GB | 1.8GB |

---

## ðŸ³ Deployment

### Docker Compose (Development)

```powershell
docker-compose up -d
```

### Kubernetes (Production)

```powershell
# Create namespace
kubectl apply -f kubernetes/namespace.yaml

# Deploy Redis
kubectl apply -f kubernetes/redis-statefulset.yaml

# Deploy workers
kubectl apply -f kubernetes/pose-extraction-deployment.yaml
kubectl apply -f kubernetes/sequence-model-deployment.yaml

# Deploy dashboard
kubectl apply -f kubernetes/dashboard-service.yaml

# Check status
kubectl get pods -n neurocombat
```

### Scaling

```powershell
# Scale motion features workers
kubectl scale deployment motion-features --replicas=4 -n neurocombat

# Auto-scaling (HPA)
kubectl autoscale deployment sequence-model \
  --cpu-percent=70 \
  --min=1 \
  --max=4 \
  -n neurocombat
```

---

## ðŸ” Observability

### Metrics (Prometheus)

```promql
# Average inference latency
rate(neurocombat_inference_duration_seconds_sum[5m])
/ rate(neurocombat_inference_duration_seconds_count[5m])

# Frames processed per second
rate(neurocombat_frames_processed_total[1m])

# Redis queue depth
neurocombat_redis_stream_length{stream_name="predictions:fighter_1"}
```

### Logs (Structured JSON)

```json
{
  "timestamp": "2025-01-11T10:30:45.123Z",
  "level": "INFO",
  "component": "pose_extraction",
  "frame_id": 12345,
  "fighter_id": "fighter_1",
  "inference_time_ms": 12.3,
  "message": "Pose extracted successfully"
}
```

### Tracing (Jaeger)

View distributed traces at http://localhost:16686

---

## ðŸ› ï¸ Development

### Code Style

```powershell
# Format with Black
black src/

# Lint with Ruff
ruff check src/

# Type check with mypy
mypy src/
```

### Pre-commit Hooks

```powershell
# Install hooks
pre-commit install

# Run manually
pre-commit run --all-files
```

---

## ðŸ¤ Contributing

1. Fork the repository
2. Create feature branch (`git checkout -b feature/amazing-feature`)
3. Commit changes (`git commit -m 'Add amazing feature'`)
4. Push to branch (`git push origin feature/amazing-feature`)
5. Open Pull Request

---

## ðŸ“„ License

This project is licensed under the MIT License - see [LICENSE](LICENSE) file.

---

## ðŸ™ Acknowledgments

- **MediaPipe** - Pose estimation
- **ByteTrack** - Multi-object tracking
- **Redis** - Stream processing
- **FastAPI** - Web framework
- **PyTorch** - Deep learning

---

## ðŸ“ž Contact

**NeuroCombat Team**
- GitHub: [@neurocombat](https://github.com/neurocombat)
- Email: team@neurocombat.ai
- Docs: https://docs.neurocombat.ai

---

**Built with â¤ï¸ for the MMA community**
